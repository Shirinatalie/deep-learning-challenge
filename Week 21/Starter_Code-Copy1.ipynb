{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shiri\\anaconda3\\envs\\dev\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "columns_to_drop = ['EIN', 'NAME']\n",
    "application_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLICATION_TYPE            17\n",
      "AFFILIATION                  6\n",
      "CLASSIFICATION              71\n",
      "USE_CASE                     5\n",
      "ORGANIZATION                 4\n",
      "STATUS                       2\n",
      "INCOME_AMT                   9\n",
      "SPECIAL_CONSIDERATIONS       2\n",
      "ASK_AMT                   8747\n",
      "IS_SUCCESSFUL                2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "unique_values_per_column = application_df.nunique()\n",
    "\n",
    "# Display the result\n",
    "print(unique_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T25        3\n",
      "T14        3\n",
      "T29        2\n",
      "T15        2\n",
      "T17        1\n",
      "Name: APPLICATION_TYPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(application_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "Other      120\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "# Choose a cutoff value (adjust as needed)\n",
    "cutoff_value = 100  \n",
    "\n",
    "# Identify application types with counts less than the cutoff value\n",
    "infrequent_application_types = application_df['APPLICATION_TYPE'].value_counts()[application_df['APPLICATION_TYPE'].value_counts() < cutoff_value].index.tolist()\n",
    "\n",
    "# Create a list of application types to be replaced\n",
    "application_types_to_replace = infrequent_application_types\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "         ...  \n",
      "C4120        1\n",
      "C8210        1\n",
      "C2561        1\n",
      "C4500        1\n",
      "C2150        1\n",
      "Name: CLASSIFICATION, Length: 71, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(classification_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'application_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# You may find it helpful to look at CLASSIFICATION value counts >1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m classification_counts \u001b[38;5;241m=\u001b[39m application_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLASSIFICATION\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Filter value counts where count is greater than 1\u001b[39;00m\n\u001b[0;32m      5\u001b[0m classification_counts_greater_than_1 \u001b[38;5;241m=\u001b[39m classification_counts[classification_counts \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'application_df' is not defined"
     ]
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "\n",
    "# Filter value counts where count is greater than 1\n",
    "classification_counts_greater_than_1 = classification_counts[classification_counts > 1]\n",
    "\n",
    "# Display the filtered value counts\n",
    "print(classification_counts_greater_than_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "cutoff_value = 100 \n",
    "\n",
    "# Identify classifications with counts less than the cutoff value\n",
    "infrequent_classifications = application_df['CLASSIFICATION'].value_counts()[application_df['CLASSIFICATION'].value_counts() < cutoff_value].index.tolist()\n",
    "\n",
    "# Create a list of classifications to be replaced\n",
    "classifications_to_replace = infrequent_classifications\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        AFFILIATION      USE_CASE  ORGANIZATION  STATUS     INCOME_AMT  \\\n",
      "0       Independent    ProductDev   Association       1              0   \n",
      "1       Independent  Preservation  Co-operative       1         1-9999   \n",
      "2  CompanySponsored    ProductDev   Association       1              0   \n",
      "3  CompanySponsored  Preservation         Trust       1    10000-24999   \n",
      "4       Independent     Heathcare         Trust       1  100000-499999   \n",
      "\n",
      "  SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
      "0                      N     5000              1                       0   \n",
      "1                      N   108590              1                       0   \n",
      "2                      N     5000              0                       0   \n",
      "3                      N     6692              1                       0   \n",
      "4                      N   142590              1                       0   \n",
      "\n",
      "   APPLICATION_TYPE_T10  ...  CLASSIFICATION_C1270  CLASSIFICATION_C1700  \\\n",
      "0                     1  ...                     0                     0   \n",
      "1                     0  ...                     0                     0   \n",
      "2                     0  ...                     0                     0   \n",
      "3                     0  ...                     0                     0   \n",
      "4                     0  ...                     0                     0   \n",
      "\n",
      "   CLASSIFICATION_C2000  CLASSIFICATION_C2100  CLASSIFICATION_C2700  \\\n",
      "0                     0                     0                     0   \n",
      "1                     1                     0                     0   \n",
      "2                     0                     0                     0   \n",
      "3                     1                     0                     0   \n",
      "4                     0                     0                     0   \n",
      "\n",
      "   CLASSIFICATION_C3000  CLASSIFICATION_C4000  CLASSIFICATION_C5000  \\\n",
      "0                     0                     0                     0   \n",
      "1                     0                     0                     0   \n",
      "2                     1                     0                     0   \n",
      "3                     0                     0                     0   \n",
      "4                     0                     0                     0   \n",
      "\n",
      "   CLASSIFICATION_C7000  CLASSIFICATION_Other  \n",
      "0                     0                     0  \n",
      "1                     0                     0  \n",
      "2                     0                     0  \n",
      "3                     0                     0  \n",
      "4                     0                     0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "# Specify the columns to one-hot encode\n",
    "columns_to_encode = ['APPLICATION_TYPE', 'CLASSIFICATION']\n",
    "\n",
    "# Use pd.get_dummies to perform one-hot encoding\n",
    "application_df_encoded = pd.get_dummies(application_df, columns=columns_to_encode)\n",
    "\n",
    "# Display the result\n",
    "print(application_df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (27439, 29)\n",
      "X_test shape: (6860, 29)\n",
      "y_train shape: (27439,)\n",
      "y_test shape: (6860,)\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Specify the features (X) and target (y)\n",
    "X = application_df_encoded.drop('IS_SUCCESSFUL', axis=1)\n",
    "y = application_df_encoded['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting arrays\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS                          int64\n",
      "ASK_AMT                         int64\n",
      "IS_SUCCESSFUL                   int64\n",
      "APPLICATION_TYPE_Other          uint8\n",
      "APPLICATION_TYPE_T10            uint8\n",
      "APPLICATION_TYPE_T19            uint8\n",
      "APPLICATION_TYPE_T3             uint8\n",
      "APPLICATION_TYPE_T4             uint8\n",
      "APPLICATION_TYPE_T5             uint8\n",
      "APPLICATION_TYPE_T6             uint8\n",
      "APPLICATION_TYPE_T7             uint8\n",
      "APPLICATION_TYPE_T8             uint8\n",
      "APPLICATION_TYPE_T9             uint8\n",
      "AFFILIATION_CompanySponsored    uint8\n",
      "AFFILIATION_Family/Parent       uint8\n",
      "AFFILIATION_Independent         uint8\n",
      "AFFILIATION_National            uint8\n",
      "AFFILIATION_Other               uint8\n",
      "AFFILIATION_Regional            uint8\n",
      "CLASSIFICATION_C1000            uint8\n",
      "CLASSIFICATION_C1200            uint8\n",
      "CLASSIFICATION_C1270            uint8\n",
      "CLASSIFICATION_C1700            uint8\n",
      "CLASSIFICATION_C2000            uint8\n",
      "CLASSIFICATION_C2100            uint8\n",
      "CLASSIFICATION_C2700            uint8\n",
      "CLASSIFICATION_C3000            uint8\n",
      "CLASSIFICATION_C4000            uint8\n",
      "CLASSIFICATION_C5000            uint8\n",
      "CLASSIFICATION_C7000            uint8\n",
      "CLASSIFICATION_Other            uint8\n",
      "USE_CASE_CommunityServ          uint8\n",
      "USE_CASE_Heathcare              uint8\n",
      "USE_CASE_Other                  uint8\n",
      "USE_CASE_Preservation           uint8\n",
      "USE_CASE_ProductDev             uint8\n",
      "ORGANIZATION_Association        uint8\n",
      "ORGANIZATION_Co-operative       uint8\n",
      "ORGANIZATION_Corporation        uint8\n",
      "ORGANIZATION_Trust              uint8\n",
      "INCOME_AMT_0                    uint8\n",
      "INCOME_AMT_1-9999               uint8\n",
      "INCOME_AMT_10000-24999          uint8\n",
      "INCOME_AMT_100000-499999        uint8\n",
      "INCOME_AMT_10M-50M              uint8\n",
      "INCOME_AMT_1M-5M                uint8\n",
      "INCOME_AMT_25000-99999          uint8\n",
      "INCOME_AMT_50M+                 uint8\n",
      "INCOME_AMT_5M-10M               uint8\n",
      "SPECIAL_CONSIDERATIONS_N        uint8\n",
      "SPECIAL_CONSIDERATIONS_Y        uint8\n",
      "dtype: object\n",
      "X_train_scaled shape: (27439, 50)\n",
      "X_test_scaled shape: (6860, 50)\n",
      "y_train shape: (27439,)\n",
      "y_test shape: (6860,)\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = application_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "application_df_encoded = pd.get_dummies(application_df, columns=categorical_columns)\n",
    "\n",
    "# Check data types after encoding\n",
    "print(application_df_encoded.dtypes)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = application_df_encoded.drop('IS_SUCCESSFUL', axis=1)\n",
    "y = application_df_encoded['IS_SUCCESSFUL']\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the scaled data into training and testing sets\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting arrays\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               6528      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14849 (58.00 KB)\n",
      "Trainable params: 14849 (58.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Create a Sequential model\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer with 128 nodes and 'relu' activation function\n",
    "nn.add(Dense(units=128, input_dim=input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer with 64 nodes and 'relu' activation function\n",
    "nn.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Output layer with a single node and 'sigmoid' activation function for binary classification\n",
    "nn.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shiri\\anaconda3\\envs\\dev\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\shiri\\anaconda3\\envs\\dev\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shiri\\anaconda3\\envs\\dev\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5657 - accuracy: 0.7238 - val_loss: 0.5620 - val_accuracy: 0.7210\n",
      "Epoch 2/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7298 - val_loss: 0.5571 - val_accuracy: 0.7267\n",
      "Epoch 3/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7309 - val_loss: 0.5575 - val_accuracy: 0.7281\n",
      "Epoch 4/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7329 - val_loss: 0.5549 - val_accuracy: 0.7296\n",
      "Epoch 5/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7332 - val_loss: 0.5550 - val_accuracy: 0.7273\n",
      "Epoch 6/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7335 - val_loss: 0.5566 - val_accuracy: 0.7315\n",
      "Epoch 7/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7341 - val_loss: 0.5532 - val_accuracy: 0.7276\n",
      "Epoch 8/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7349 - val_loss: 0.5534 - val_accuracy: 0.7289\n",
      "Epoch 9/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7345 - val_loss: 0.5519 - val_accuracy: 0.7305\n",
      "Epoch 10/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7349 - val_loss: 0.5524 - val_accuracy: 0.7286\n",
      "Epoch 11/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7344 - val_loss: 0.5536 - val_accuracy: 0.7294\n",
      "Epoch 12/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7354 - val_loss: 0.5517 - val_accuracy: 0.7302\n",
      "Epoch 13/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7372 - val_loss: 0.5523 - val_accuracy: 0.7287\n",
      "Epoch 14/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7365 - val_loss: 0.5534 - val_accuracy: 0.7290\n",
      "Epoch 15/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7361 - val_loss: 0.5539 - val_accuracy: 0.7274\n",
      "Epoch 16/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7369 - val_loss: 0.5516 - val_accuracy: 0.7290\n",
      "Epoch 17/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7369 - val_loss: 0.5546 - val_accuracy: 0.7271\n",
      "Epoch 18/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7369 - val_loss: 0.5526 - val_accuracy: 0.7290\n",
      "Epoch 19/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7366 - val_loss: 0.5535 - val_accuracy: 0.7286\n",
      "Epoch 20/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7379 - val_loss: 0.5535 - val_accuracy: 0.7284\n",
      "Epoch 21/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7384 - val_loss: 0.5537 - val_accuracy: 0.7283\n",
      "Epoch 22/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7371 - val_loss: 0.5544 - val_accuracy: 0.7280\n",
      "Epoch 23/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7381 - val_loss: 0.5549 - val_accuracy: 0.7290\n",
      "Epoch 24/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7384 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
      "Epoch 25/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7377 - val_loss: 0.5533 - val_accuracy: 0.7313\n",
      "Epoch 26/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7384 - val_loss: 0.5524 - val_accuracy: 0.7303\n",
      "Epoch 27/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7383 - val_loss: 0.5544 - val_accuracy: 0.7287\n",
      "Epoch 28/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7393 - val_loss: 0.5533 - val_accuracy: 0.7308\n",
      "Epoch 29/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7381 - val_loss: 0.5534 - val_accuracy: 0.7296\n",
      "Epoch 30/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7386 - val_loss: 0.5540 - val_accuracy: 0.7284\n",
      "Epoch 31/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7387 - val_loss: 0.5522 - val_accuracy: 0.7312\n",
      "Epoch 32/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7387 - val_loss: 0.5534 - val_accuracy: 0.7286\n",
      "Epoch 33/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7385 - val_loss: 0.5542 - val_accuracy: 0.7264\n",
      "Epoch 34/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7391 - val_loss: 0.5558 - val_accuracy: 0.7302\n",
      "Epoch 35/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7392 - val_loss: 0.5549 - val_accuracy: 0.7280\n",
      "Epoch 36/50\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7390 - val_loss: 0.5564 - val_accuracy: 0.7284\n",
      "Epoch 37/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7401 - val_loss: 0.5566 - val_accuracy: 0.7265\n",
      "Epoch 38/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7398 - val_loss: 0.5540 - val_accuracy: 0.7305\n",
      "Epoch 39/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7404 - val_loss: 0.5539 - val_accuracy: 0.7289\n",
      "Epoch 40/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7397 - val_loss: 0.5574 - val_accuracy: 0.7262\n",
      "Epoch 41/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7395 - val_loss: 0.5561 - val_accuracy: 0.7281\n",
      "Epoch 42/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7392 - val_loss: 0.5550 - val_accuracy: 0.7274\n",
      "Epoch 43/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7404 - val_loss: 0.5581 - val_accuracy: 0.7296\n",
      "Epoch 44/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7390 - val_loss: 0.5560 - val_accuracy: 0.7281\n",
      "Epoch 45/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7412 - val_loss: 0.5559 - val_accuracy: 0.7283\n",
      "Epoch 46/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7397 - val_loss: 0.5620 - val_accuracy: 0.7277\n",
      "Epoch 47/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7406 - val_loss: 0.5575 - val_accuracy: 0.7267\n",
      "Epoch 48/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7406 - val_loss: 0.5600 - val_accuracy: 0.7284\n",
      "Epoch 49/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7403 - val_loss: 0.5599 - val_accuracy: 0.7290\n",
      "Epoch 50/50\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7398 - val_loss: 0.5600 - val_accuracy: 0.7262\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - loss: 0.5600 - accuracy: 0.7262 - 197ms/epoch - 917us/step\n",
      "Loss: 0.5600032806396484, Accuracy: 0.7262390851974487\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "model_filename = 'AlphabetSoupCharity_Optimization.keras'\n",
    "\n",
    "# Save the model to the native Keras format\n",
    "nn.save(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
